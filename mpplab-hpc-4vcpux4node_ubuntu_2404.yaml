blueprint_name: mpplab-slurm-c3-4vcpu-4node-250gb-storage
terraform_backend_defaults:
  type: local
vars:
  project_id: mpplab-482405
  deployment_name: mpplab-c3-4vcpu-4node-rocky
  region: asia-south1
  zone: asia-south1-b
  
deployment_groups:
- group: primary
  modules:
  - id: network
    source: modules/network/vpc
    
  - id: allow_iap_ssh
    source: modules/network/firewall-rules
    use: [network]
    settings:
      ingress_rules:
        - name: allow-ssh-from-iap
          description: "Allow SSH via IAP tunnel"
          priority: 1000
          source_ranges: ["35.235.240.0/20"]
          allow:
            - protocol: tcp
              ports: ["22"]
              
  - id: shared_storage
    source: modules/file-system/filestore
    use: [network]
    settings:
      local_mount: /data
      filestore_tier: BASIC_HDD
      size_gb: 1024
  
  - id: compute_nodeset
    source: community/modules/compute/schedmd-slurm-gcp-v6-nodeset
    use: [network]
    settings:
      node_count_dynamic_max: 4
      machine_type: c3-highmem-4
      disk_type: pd-balanced
      disk_size_gb: 50
      zone: asia-south1-b
      instance_image:
        name: ubuntu-2404-slurm-ready-v14 
        project: mpplab-482405
    

  - id: compute_partition
    source: community/modules/compute/schedmd-slurm-gcp-v6-partition
    use: [compute_nodeset]
    settings:
      partition_name: compute
      is_default: true
  
  - id: slurm_login
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-login
    use: [network]
    settings:
      machine_type: n2-standard-4
      instance_image:
        family: hpc-rocky-linux-8
        project: cloud-hpc-image-public
      enable_oslogin: true
  
  - id: slurm_controller
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-controller
    use: [network, shared_storage, compute_partition, slurm_login]
    settings:
      enable_oslogin: true
      instance_image:
        family: hpc-rocky-linux-8
        project: cloud-hpc-image-public